from transformers import BertTokenizer, BertForSequenceClassification
import torch

model_path = f'saved_models/2023-11-02_12-55-16/model'
tokenizer_path = f'saved_models/2023-11-02_12-55-16/tokenizer'

def interactive_sentiment_analysis():
    # load trained model and tokenizer
    model = BertForSequenceClassification.from_pretrained(f'C:/Users/user/pythonProject/{model_path}')
    tokenizer = BertTokenizer.from_pretrained(f'C:/Users/user/pythonProject/{tokenizer_path}')

    while True: # interactive loop
        user_input = input("input the sentence (or 'exit' to leave): ") # end
        if user_input.lower() == 'exit':
            break

        encoding = tokenizer(user_input, truncation=True, padding=True, max_length=1023, return_tensors='pt') # 1023 is max length of sentence

        with torch.no_grad():
            outputs = model(**encoding)
        preds = torch.argmax(outputs.logits, dim=1).item() # model's prediction

        sentiment_label = {0: 'positive', 1: 'neutral', 2: 'negative'}
        sentiment = sentiment_label[preds] # convert the reply

        print(f"Sentiment: {sentiment}")

# running
if __name__ == "__main__":
    interactive_sentiment_analysis()


#model, which get text as input and response the mood of it (0,1,2)
'''
def get_sentiment(text):
    encoding = tokenizer(text, truncation=True, padding=True, max_length=1023, return_tensors='pt') # 1024+ were cut off
    with torch.no_grad(): # turn the gradient response off
        outputs = model(**encoding)
        preds = torch.argmax(outputs.logits, dim=1).item() # use softmax for output
    sentiment_dict = {0: 'positive', 1: 'neutral', 2: 'negative'}
    return sentiment_dict[preds]
'''
